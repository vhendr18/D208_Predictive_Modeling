{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:turquoise\">D208 Performance Assessment NBM2 Task 1</span>\n",
    "## <span style=\"color:turquoise\">Multiple Regression for Predictive Modeling</span>\n",
    "&emsp;Ryan L. Buchanan\n",
    "<br>&emsp;Student ID:  001826691\n",
    "<br>&emsp;Masters Data Analytics (12/01/2020)\n",
    "<br>&emsp;Program Mentor:  Dan Estes\n",
    "<br>&emsp;(385) 432-9281 (MST)\n",
    "<br>&emsp;rbuch49@wgu.edu\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>A1. Research Question</b>:</span>\n",
    "How much many GBs of data will a customer use yearly?  Can this be predicted accurately from a list of explanatory variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>A2. Objectives & Goals</b>:</span>\n",
    "Stakeholders in the company will benefit by knowing, with some measure of confidence, how much data a customer might predictably use.\n",
    "This will provide weight for decisions in whether or not to expand customer data limits, provide unlimited (or metered) media streaming & expand company cloud computing resources for increased bandwidth demands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>B1. Summary of Assumptions</b>:</span>\n",
    "Assumptions of a multiple regression model include:\n",
    "* There is a linear relationship between the dependent variables & the independent variables.\n",
    "* The independent variables are not too highly correlated with each other.\n",
    "* y<sub>i</sub> observations are selected independently & randomly from the population.\n",
    "* Residuals should normally distributed with a mean of zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>B2. Tool Benefits</b>:</span>\n",
    "Python & IPython Jupyter notebooks will be used to support this analysis.  Python offers very intuitive, simple & versatile programming style & syntax, as well as a large system of mature packages for data science & machine learning.  Since, Python is cross-platform, it will work well whether consumers of the analysis are using Windows PCs or a MacBook laptop.  It is fast when compared with other possible programming languages like R or MATLAB (Massaron, p. 8).\n",
    "<br> &emsp; Also, there is strong support for Python as the most popular data science programming language in popular literature & media (<a target=\"_blank\" href=\"https://www.cbtnuggets.com/blog/technology/data/why-data-scientists-love-python\">CBTNuggets</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>B3. Appropriate Technique</b>:</span>\n",
    "Multiple regression is an appropriate technique to analyze the research question because our target variable, predicting a real number of GBs per year, is a continuous variable (how much data is used).  Also, perhaps there are several (versus simply one) explanatory variables (area type, job, children, age, income, etc.) that will add to our understanding when trying to predict how much data a customer will use in a given year.  When adding or removing independent variables from our regression equation, we will find out whether or not they have a positive or negative relationship to our target variable & how that might affect company decisions on marketing segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>C1. Data Goals</b>:</span>\n",
    "\n",
    "My approach will include:\n",
    "<br>&ensp; 1. Back up my data and the process I am following as a copy to my machine and, since this is a manageable dataset, to GitHub using command line and gitbash.\n",
    "<br>&ensp; 2. Read the data set into Python using Pandas' read_csv command.\n",
    "<br>&ensp; 3. Evaluate the data struture to better understand input data.\n",
    "<br>&ensp; 4. Naming the dataset as a the variable \"churn_df\" and subsequent useful slices of the dataframe as \"df\".\n",
    "<br>&ensp; 5. Examine potential misspellings, awkward variable naming & missing data.\n",
    "<br>&ensp; 6. Find outliers that may create or hide statistical significance using histograms.\n",
    "<br>&ensp; 7. Imputing records missing data with meaningful measures of central tendency (mean, median or mode) or simply remove outliers that are several standard deviations above the mean.\n",
    "\n",
    "Most relevant to our decision making process is the <b>dependent variable</b> of \"Bandwidth_GB_Year\" (the average yearly amount of data used, in GB, per customer) which will be our <b>continuous target variable</b>. We need to train & then test our machine on our given dataset to develop a model that will give us an idea of how much data a customer may use given the amounts used by known customers given their respective data points for selected predictor variables.  \n",
    "\n",
    "<br>In cleaning the data, we may discover relevance of the <b>continuous predictor variables<b>: \n",
    "* Children\n",
    "* Income\n",
    "* Outage_sec_perweek\n",
    "* Yearly_equip_failure\n",
    "* Tenure (the number of months the customer has stayed with the provider)\n",
    "* MonthlyCharge\n",
    "* Bandwidth_GB_Year    \n",
    "    \n",
    "<br>Likewise, we may discover relevance of the <b>categorical predictor variables</b> (all binary categorical with only two values, \"Yes\" or \"No\", except where noted): \n",
    "* Techie: Whether the customer considers themselves technically inclined (based on\n",
    "customer questionnaire when they signed up for services) (yes, no)\n",
    "* Contract: The contract term of the customer (month-to-month, one year, two year)\n",
    "* Port_modem: Whether the customer has a portable modem (yes, no)\n",
    "* Tablet: Whether the customer owns a tablet such as iPad, Surface, etc. (yes, no)\n",
    "* InternetService: Customerâ€™s internet service provider (DSL, fiber optic, None)\n",
    "* Phone: Whether the customer has a phone service (yes, no)\n",
    "* Multiple: Whether the customer has multiple lines (yes, no)\n",
    "* OnlineSecurity: Whether the customer has an online security add-on (yes, no)\n",
    "* OnlineBackup: Whether the customer has an online backup add-on (yes, no)\n",
    "* DeviceProtection: Whether the customer has device protection add-on (yes, no)\n",
    "* TechSupport: Whether the customer has a technical support add-on (yes, no)\n",
    "* StreamingTV: Whether the customer has streaming TV (yes, no)\n",
    "* StreamingMovies: Whether the customer has streaming movies (yes, no)\n",
    "    \n",
    "<br>Finally, <b>discrete ordinal predictor variables</b> from the survey responses from customers regarding various customer service features may be relevant in the decision-making process. In the surveys, customers provided ordinal numerical data by rating 8 customer service factors on a scale of 1 to 8 (1 = most important, 8 = least important): \n",
    "    \n",
    "* Item1: Timely response\n",
    "* Item2: Timely fixes\n",
    "* Item3: Timely replacements\n",
    "* Item4: Reliability\n",
    "* Item5: Options\n",
    "* Item6: Respectful response\n",
    "* Item7: Courteous exchange\n",
    "* Item8: Evidence of active listening\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>C2. Summary Statistics</b>:</span>\n",
    "Discuss the summary statistics, including the target variable and all predictor variables that you will need to gather from the data set to answer the research question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>C3. Steps to Prepare Data</b>:</span>\n",
    "Explain the steps used to prepare the data for the analysis, including the annotated code.\n",
    "\n",
    "* Imputing records missing data with meaningful measures of central tendency (mean, median or mode) or simply remove outliers that are several standard deviations above the mean.\n",
    "\n",
    "<span style=\"color:red\">*</span>\n",
    "\n",
    "<span style=\"color:red\">*</span>\n",
    "\n",
    "<span style=\"color:red\">*</span>\n",
    "\n",
    "\n",
    "* Finally, the prepared dataset will be extracted & provided as \"churn_prepared.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Increase Jupyter display cell-width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard data science imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "# Visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Statistics packages\n",
    "import pylab\n",
    "from pylab import rcParams\n",
    "import statsmodels.api as sm\n",
    "import statistics\n",
    "from scipy import stats\n",
    "\n",
    "# Scikit-learn\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Import chisquare from SciPy.stats\n",
    "from scipy.stats import chisquare\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Ignore Warning Code\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change color of Matplotlib font\n",
    "import matplotlib as mpl\n",
    "\n",
    "COLOR = 'white'\n",
    "mpl.rcParams['text.color'] = COLOR\n",
    "mpl.rcParams['axes.labelcolor'] = COLOR\n",
    "mpl.rcParams['xtick.color'] = COLOR\n",
    "mpl.rcParams['ytick.color'] = COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set into Pandas dataframe\n",
    "churn_df = pd.read_csv('Data/churn_clean.csv')\n",
    "\n",
    "# Rename last 8 survey columns for better description of variables\n",
    "churn_df.rename(columns = {'Item1':'TimelyResponse', \n",
    "                    'Item2':'Fixes', \n",
    "                     'Item3':'Replacements', \n",
    "                     'Item4':'Reliability', \n",
    "                     'Item5':'Options', \n",
    "                     'Item6':'Respectfulness', \n",
    "                     'Item7':'Courteous', \n",
    "                     'Item8':'Listening'}, \n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Churn dataframe\n",
    "churn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Dataframe Columns\n",
    "df = churn_df.columns\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of records and columns of dataset\n",
    "churn_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe Churn dataset statistics\n",
    "churn_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove less meaningful demographic variables from statistics description\n",
    "churn_df = churn_df.drop(columns=['CaseOrder', 'Customer_id', 'Interaction', 'UID', 'City', \n",
    "                            'State', 'County', 'Zip', 'Lat', 'Lng', 'Population', \n",
    "                            'Area', 'TimeZone', 'Job', 'Marital'])\n",
    "churn_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover missing data points within dataset\n",
    "data_nulls = churn_df.isnull().sum()\n",
    "print(data_nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>C4. Visualizations</b>:</span>\n",
    "Generate univariate and bivariate visualizations of the distributions of variables in the cleaned data set. Include the target variable in your bivariate visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values in dataset\n",
    "\n",
    "# Install appropriate library\n",
    "!pip install missingno\n",
    "\n",
    "# Importing the libraries\n",
    "import missingno as msno\n",
    "\n",
    "# Visualize missing values as a matrix\n",
    "msno.matrix(churn_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''No need to impute an missing values as the dataset appears complete/cleaned'''\n",
    "# Impute missing fields for variables Children, Age, Income, Tenure and Bandwidth_GB_Year with median or mean\n",
    "# churn_df['Children'] = churn_df['Children'].fillna(churn_df['Children'].median())\n",
    "# churn_df['Age'] = churn_df['Age'].fillna(churn_df['Age'].median())\n",
    "# churn_df['Income'] = churn_df['Income'].fillna(churn_df['Income'].median())\n",
    "# churn_df['Tenure'] = churn_df['Tenure'].fillna(churn_df['Tenure'].median())\n",
    "# churn_df['Bandwidth_GB_Year'] = churn_df['Bandwidth_GB_Year'].fillna(churn_df['Bandwidth_GB_Year'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create histograms of contiuous & categorical variables\n",
    "churn_df[['Children', 'Age', 'Income', 'Tenure', 'MonthlyCharge', 'Bandwidth_GB_Year']].hist()\n",
    "plt.savefig('churn_pyplot.jpg')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Seaborn boxplots for continuous & categorical variables\n",
    "sns.boxplot('MonthlyCharge', data = churn_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot('Bandwidth_GB_Year', data = churn_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It appears that anomolies have been removed from the dataset present \"churn_clean.csv\" as there are no remaining outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's run some scatterplots to get an idea of our linear relationships with bandwidth usage & some of the respective predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run scatterplots to show direct or inverse relationships between target & independent variables\n",
    "sns.scatterplot(x=churn_df['Children'], y=churn_df['Bandwidth_GB_Year'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=churn_df['Age'], y=churn_df['Bandwidth_GB_Year'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=churn_df['Income'], y=churn_df['Bandwidth_GB_Year'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=churn_df['Tenure'], y=churn_df['Bandwidth_GB_Year'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=churn_df['MonthlyCharge'], y=churn_df['Bandwidth_GB_Year'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for heatmap bivariate analysis of correlation\n",
    "churn_bivariate = churn_df[['Bandwidth_GB_Year', 'Children', 'Age', 'Income', \n",
    "                            'Outage_sec_perweek', 'Yearly_equip_failure', \n",
    "                            'Tenure', 'MonthlyCharge']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Seaborn heatmap\n",
    "sns.heatmap(churn_bivariate.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again, it appears that Tenure is the predictor for most of the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scree plots & Principal Component Analysis (PCA) -> <span style=\"color:red\"><i>which suggests we should only use <b>certain</b> variables</i></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up for scree plots & PCA\n",
    "\n",
    "# For a scree plot import matplotlib & seaborn libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import Scikit Learn PCA application\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Normalize the data\n",
    "churn_normalized = (data - data.mean()) / data.std()\n",
    "\n",
    "# Select number of components to extract\n",
    "pca = PCA(n_components = data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of PCA names\n",
    "churn_numeric = data[['Tenure', 'MonthlyCharge', 'Bandwidth_GB_Year', 'Responses', \n",
    "                       'Fixes', 'Replacements', 'Reliability', 'Options', \n",
    "                       'Respectfulness', 'Courteous', 'Listening']]\n",
    "pcs_names = []\n",
    "for i, col in enumerate(churn_numeric.columns):\n",
    "    pcs_names.append('PC' + str(i + 1))\n",
    "print(pcs_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call PCA application & convert the dataset of 11 variables into a dataset of 11 components\n",
    "pca.fit(churn_normalized)\n",
    "churn_pca = pd.DataFrame(pca.transform(churn_normalized),\n",
    "                        columns = pcs_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the scree plot\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the eigenvalues\n",
    "cov_matrix = np.dot(churn_normalized.T, churn_normalized) / data.shape[0]\n",
    "eigenvalues = [np.dot(eigenvector.T, np.dot(cov_matrix, eigenvector)) \n",
    "               for eigenvector in pca.components_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the eigenvalues\n",
    "plt.plot(eigenvalues)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the fewest components \n",
    "for pc, var in zip(pcs_names, np.cumsum(pca.explained_variance_ratio_)):\n",
    "    print(pc, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above, we see that 86% of variance is explained by 7 components\n",
    "# Create a rotation \n",
    "rotation = pd.DataFrame(pca.components_.T, columns = pcs_names, index = churn_numeric.columns)\n",
    "print(rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output loadings for components\n",
    "loadings = pd.DataFrame(pca.components_.T,\n",
    "                       columns = pcs_names,\n",
    "                       index = data.columns)\n",
    "loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, extract reduced dataset & print 3 components\n",
    "churn_reduced = churn_pca.iloc[ : , 0:3]\n",
    "print(churn_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is clearly a direct linear relationship between customer tenure with the telecom company & the amount of data (in GBs) that is being used.  Let's run a simple linear regression model on those two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df['intercept'] = 1\n",
    "lm_bandwidth = sm.OLS(churn_df['Bandwidth_GB_Year'], churn_df[['Children', 'Tenure', 'intercept']]).fit()\n",
    "print(lm_bandwidth.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Multiple Linear Regression Model\n",
    "With <b><i>seven</i></b> indpendent variables: \n",
    "<br><br>&emsp;<span style=\"color:gold\">y = 104.85 + 30.86 * Children - 3.31 * Age + 0.00 * Income - 0.26 * Outage_sec_perweek + 0.67 * Yearly_equip_failure + 82.01 * Tenure + 3.28 * MonthlyCharge</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced Multiple Linear Regression Model\n",
    "With two indpendent variables: y = 497.78 + 31.18 * Children + 81.94 * Tenure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>C5. Prepared Dataset</b>:</span>\n",
    "Provide a copy of the prepared data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Clean dataset\n",
    "churn_df.to_csv('churn_prepared.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:Gold'><b>Part IV: Model Comparison and Analysis</b></span>\n",
    "\n",
    "D.  Compare an initial and a reduced multiple regression model by doing the following:\n",
    "\n",
    "1.  Construct an initial multiple regression model from all predictors that were identified in Part C2.\n",
    "\n",
    "2.  Justify a statistically based variable selection procedure and a model evaluation metric to reduce the initial model in a way that aligns with the research question.\n",
    "\n",
    "3.  Provide a reduced multiple regression model that includes both categorical and continuous variables.\n",
    "\n",
    "\n",
    "\n",
    "<span style='color:red'>Note: The output should include a screenshot of each model.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>D1. Initial Model</b></span>\n",
    "Construct an initial multiple regression model from <span style=\"color:red\"><i>all predictors that were identified in Part C2</i></span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop the initial estimated regression equation that could be used to predict the Bandwidth_GB_Year, \n",
    "# given the continuous variables\n",
    "churn_df['intercept'] = 1\n",
    "lm_bandwidth = sm.OLS(churn_df['Bandwidth_GB_Year'], churn_df[['Children', 'Age', \n",
    "                                                               'Income',\n",
    "                                                               'Outage_sec_perweek', \n",
    "                                                               'Yearly_equip_failure', \n",
    "                                                               'Tenure', 'MonthlyCharge', \n",
    "                                                               'intercept']]).fit()\n",
    "print(lm_bandwidth.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on an R<sup>2</sup> value = 0.989.  So, 99% of the variation is explained by this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>D2. Justification of Model Reduction</b></span>\n",
    "Justify a statistically based variable selection procedure and a model evaluation metric to reduce the initial model in a way that aligns with the research question.\n",
    "\n",
    "<span style='color:red'>Note: Heatmap of missing values vs observed</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>D3. Reduced Multiple Regression Model</b></span>\n",
    "Provide a reduced multiple regression model that includes both categorical and continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well, there it is.  Removing all the other predictor variables except \"Tenure\" & our model still explains 98% of the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:Gold'><b>Part IV: E</b></span>\n",
    "E.  Analyze the data set using your reduced multiple regression model by doing the following:\n",
    "\n",
    "1.  Explain your data analysis process by comparing the initial and reduced multiple regression models, including the following elements:\n",
    "<ul>\n",
    "    <li>\n",
    "    the logic of the variable selection technique\n",
    "    </li>\n",
    "    <li>\n",
    "    the model evaluation metric\n",
    "    </li>\n",
    "    <li>\n",
    "    a residual plot\n",
    "    </li>\n",
    "</ul>\n",
    "2.  Provide the output and any calculations of the analysis you performed, including the modelâ€™s residual error.\n",
    "\n",
    "\n",
    "\n",
    "<span style='color:red'>Note: The output should include the predictions from the refined model you used to perform the analysis. </span>\n",
    "\n",
    "\n",
    "\n",
    "3.  Provide the code used to support the implementation of the multiple regression models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>E1. Model Comparison</b></span>\n",
    "Explain your data analysis process by comparing the initial and reduced multiple regression models, including the following elements:\n",
    "<ul>\n",
    "    <li>\n",
    "    the logic of the variable selection technique\n",
    "    </li>\n",
    "    <li>\n",
    "    the model evaluation metric\n",
    "    </li>\n",
    "    <li>\n",
    "    a residual plot\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<span style='color:red'>Note: Verbatim from fasttrack description of analysis of Titanic dataset, \n",
    "<br>\"Since male is the dummy variable, being male reduces the log odds by 2.75 while a unit increase in age reduces log odds by 0.037.\" </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>E2. Output & Calculations</b></span>\n",
    "Provide the output and any calculations of the analysis you performed, including the modelâ€™s residual error.\n",
    "\n",
    "\n",
    "\n",
    "<span style='color:red'>Note: The output should include the predictions from the refined model you used to perform the analysis. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>E3. Code</b></span>\n",
    "Provide the code used to support the implementation of the multiple regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:Gold'><b>Part V: Data Summary and Implications</b></span>\n",
    "\n",
    "F.  Summarize your findings and assumptions by doing the following:\n",
    "\n",
    "1.  Discuss the results of your data analysis, including the following elements:\n",
    "<ul>\n",
    "    <li>\n",
    "    a regression equation for the reduced model\n",
    "    </li>\n",
    "    <li>\n",
    "    an interpretation of coefficients of the statistically significant variables of the model\n",
    "    </li>\n",
    "    <li>\n",
    "    the statistical and practical significance of the model\n",
    "    </li>\n",
    "    <li>\n",
    "    the limitations of the data analysis\n",
    "    </li>\n",
    "</ul>\n",
    "2.  Recommend a course of action based on your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>F1. Results</b></span>\n",
    " Discuss the results of your data analysis, including the following elements:\n",
    "<ul>\n",
    "    <li>\n",
    "    a regression equation for the reduced model\n",
    "    </li>\n",
    "    <li>\n",
    "    an interpretation of coefficients of the statistically significant variables of the model\n",
    "    </li>\n",
    "    <li>\n",
    "    the statistical and practical significance of the model\n",
    "    </li>\n",
    "    <li>\n",
    "    the limitations of the data analysis\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>F2. Recommendations</b></span>\n",
    "Recommend a course of action based on your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:Gold'><b>Part VI: Demonstration</b></span>\n",
    "\n",
    "G.  Provide a Panopto video recording that includes all of the following elements:\n",
    "\n",
    "â€¢  a demonstration of the functionality of the code used for the analysis\n",
    "\n",
    "â€¢  an identification of the version of the programming environment\n",
    "\n",
    "â€¢  a comparison of the two multiple regression models you used in your analysis\n",
    "\n",
    "â€¢  an interpretation of the coefficients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>G. Video</b></span>\n",
    "<span style=\"color:red\">link</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">H. Sources for Third-Party Code</span>\n",
    "\n",
    "Kaggle. (2018, May 01). Bivariate plotting with pandas. Kaggle. https://www.kaggle.com/residentmario/bivariate-plotting-with-pandas#\n",
    "\n",
    "<br> Sree. &ensp; (2020, October 26). &ensp; <i>Predict Customer Churn in Python.</i> &ensp; Towards Data Science. https://towardsdatascience.com/predict-customer-churn-in-python-e8cd6d3aaa7\n",
    "\n",
    "<br> Wikipedia. (2021, May 31). Bivariate Analysis. https://en.wikipedia.org/wiki/Bivariate_analysis#:~:text=Bivariate%20analysis%20is%20one%20of,the%20empirical%20relationship%20between%20them.&text=Like%20univariate%20analysis%2C%20bivariate%20analysis%20can%20be%20descriptive%20or%20inferential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">I. Sources</span>\n",
    "\n",
    "Ahmad, A. K., Jafar, A & Aljoumaa, K. &ensp; (2019, March 20). &ensp; <i>Customer churn prediction in telecom using machine learning in big data platform</i>. &ensp; Journal of Big Data. https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0191-6\n",
    "\n",
    "<br> Altexsoft. &ensp; (2019, March 27). &ensp; <i>Customer Churn Prediction Using Machine Learning: Main Approaches and Models</i>. &ensp; Altexsoft. &ensp; &ensp; https://www.altexsoft.com/blog/business/customer-churn-prediction-for-subscription-businesses-using-machine-learning-main-approaches-and-models/\n",
    "\n",
    "<br> Bruce, P., Bruce A. & Gedeck P. &ensp; (2020). &ensp; <i>Practical Statistics for Data Scientists</i>. &ensp; O'Reilly.\n",
    "\n",
    "<br> CBTNuggets. &ensp; (2018, September 20). &ensp; <i>Why Data Scientists Love Python</i>. &ensp; https://www.cbtnuggets.com/blog/technology/data/why-data-scientists-love-python\n",
    "\n",
    "<br> Freedman, D. Pisani, R. & Purves, R. &ensp; (2018). &ensp; <i>Statistics</i>. &ensp; W. W. Norton & Company, Inc. \n",
    "\n",
    "<br> Frohbose, F. &ensp; (2020, November 24). &ensp; <i>Machine Learning Case Study: Telco Customer Churn Prediction</i>.  &ensp; Towards Data Science. &ensp; https://towardsdatascience.com/machine-learning-case-study-telco-customer-churn-prediction-bc4be03c9e1d\n",
    "\n",
    "<br> Griffiths, D. &ensp; (2009). &ensp; <i>A Brain-Friendly Guide: Head First Statistics</i>. &ensp; O'Reilly.\n",
    "\n",
    "<br> Grus, J. &ensp; (2015). &ensp; <i>Data Science from Scratch</i>. &ensp; O'Reilly.\n",
    "\n",
    "<br> Massaron, L. & Boschetti, A. &ensp; (2016). &ensp; <i>Regression Analysis with Python</i>. &ensp; Packt Publishing.\n",
    "\n",
    "<br> McKinney, W. &ensp; (2018). &ensp; <i>Python for Data Analysis</i>. O'Reilly.\n",
    "\n",
    "<br> Rossant, C. (2018). &ensp; <i>IPython Interactive Computing & Visualization Cookbook, 2nd Edition</i>. &ensp; Packt Publishing.\n",
    "\n",
    "<br> Rossant, C. (2015). &ensp; <i>Learning IPython Interactive Computing & Visualization, 2nd Edition</i>. &ensp; Packt Publishing.\n",
    "\n",
    "<br> VanderPlas, J. &ensp; (2017). &ensp; <i>Python Data Science Handbook</i>. &ensp; O'Reilly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/brpy/colab-pdf/master/colab_pdf.py\n",
    "from colab_pdf import colab_pdf\n",
    "colab_pdf('D208_Performance_Assessment_NBM2_Task_1.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
