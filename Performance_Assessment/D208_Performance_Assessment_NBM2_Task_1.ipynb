{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:turquoise\">D208 Performance Assessment NBM2 Task 1</span>\n",
    "## <span style=\"color:turquoise\">Multiple Regression for Predictive Modeling</span>\n",
    "&emsp;Ryan L. Buchanan\n",
    "<br>&emsp;Student ID:  001826691\n",
    "<br>&emsp;Masters Data Analytics (12/01/2020)\n",
    "<br>&emsp;Program Mentor:  Dan Estes\n",
    "<br>&emsp;(385) 432-9281 (MST)\n",
    "<br>&emsp;rbuch49@wgu.edu\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>A1. Research Question</b>:</span>\n",
    "How much many GBs of data will a customer use yearly?  Can this be predicted accurately from a list of explanatory variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>A2. Objectives & Goals</b>:</span>\n",
    "Stakeholders in the company will benefit by knowing, with some measure of confidence, how much data a customer might predictably use.\n",
    "This will provide weight for decisions in whether or not to expand customer data limits, provide unlimited (or metered) media streaming & expand company cloud computing resources for increased bandwidth demands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>B1. Summary of Assumptions</b>:</span>\n",
    "Assumptions of a multiple regression model include:\n",
    "* There is a linear relationship between the dependent variables & the independent variables.\n",
    "* The independent variables are not too highly correlated with each other.\n",
    "* y<sub>i</sub> observations are selected independently & randomly from the population.\n",
    "* Residuals should normally distributed with a mean of zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>B2. Tool Benefits</b>:</span>\n",
    "Python & IPython Jupyter notebooks will be used to support this analysis.  Python offers very intuitive, simple & versatile programming style & syntax, as well as a large system of mature packages for data science & machine learning.  Since, Python is cross-platform, it will work well whether consumers of the analysis are using Windows PCs or a MacBook laptop.  It is fast when compared with other possible programming languages like R or MATLAB (Massaron, p. 8).\n",
    "<br> &emsp; Also, there is strong support for Python as the most popular data science programming language in popular literature & media (<a target=\"_blank\" href=\"https://www.cbtnuggets.com/blog/technology/data/why-data-scientists-love-python\">CBTNuggets</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>B3. Appropriate Technique</b>:</span>\n",
    "Multiple regression is an appropriate technique to analyze the research question because our target variable, predicting a real number of GBs per year, is a continuous variable (how much data is used).  Also, perhaps there are several (versus simply one) explanatory variables (area type, job, children, age, income, etc.) that will add to our understanding when trying to predict how much data a customer will use in a given year.  When adding or removing independent variables from our regression equation, we will find out whether or not they have a positive or negative relationship to our target variable & how that might affect company decisions on marketing segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>C1. Data Goals</b>:</span>\n",
    "\n",
    "My approach will include:\n",
    "<br>&ensp; 1. Back up my data and the process I am following as a copy to my machine and, since this is a manageable dataset, to GitHub using command line and gitbash.\n",
    "<br>&ensp; 2. Read the data set into Python using Pandas' read_csv command.\n",
    "<br>&ensp; 3. Evaluate the data struture to better understand input data.\n",
    "<br>&ensp; 4. Naming the dataset as a the variable \"churn_df\" and subsequent useful slices of the dataframe as \"df\".\n",
    "<br>&ensp; 5. Examine potential misspellings, awkward variable naming & missing data.\n",
    "<br>&ensp; 6. Find outliers that may create or hide statistical significance using histograms.\n",
    "<br>&ensp; 7. Imputing records missing data with meaningful measures of central tendency (mean, median or mode) or simply remove outliers that are several standard deviations above the mean.\n",
    "\n",
    "Most relevant to our decision making process is the <b>dependent variable</b> of \"Bandwidth_GB_Year\" (the average yearly amount of data used, in GB, per customer) which will be our <b>continuous target variable</b>. We need to train & then test our machine on our given dataset to develop a model that will give us an idea of how much data a customer may use given the amounts used by known customers given their respective data points for selected predictor variables.  \n",
    "\n",
    "<br>In cleaning the data, we may discover relevance of the <b>continuous predictor variables</b>: \n",
    "* Children\n",
    "* Income\n",
    "* Outage_sec_perweek\n",
    "* Email\n",
    "* Contacts    \n",
    "* Yearly_equip_failure\n",
    "* Tenure (the number of months the customer has stayed with the provider)\n",
    "* MonthlyCharge\n",
    "* Bandwidth_GB_Year    \n",
    "    \n",
    "<br>Likewise, we may discover relevance of the <b>categorical predictor variables</b> (all binary categorical with only two values, \"Yes\" or \"No\", except where noted): \n",
    "* Churn: Whether the customer discontinued service within the last month (yes, no)\n",
    "* Techie: Whether the customer considers themselves technically inclined (based on\n",
    "customer questionnaire when they signed up for services) (yes, no)\n",
    "* Contract: The contract term of the customer (month-to-month, one year, two year)\n",
    "* Port_modem: Whether the customer has a portable modem (yes, no)\n",
    "* Tablet: Whether the customer owns a tablet such as iPad, Surface, etc. (yes, no)\n",
    "* InternetService: Customerâ€™s internet service provider (DSL, fiber optic, None)\n",
    "* Phone: Whether the customer has a phone service (yes, no)\n",
    "* Multiple: Whether the customer has multiple lines (yes, no)\n",
    "* OnlineSecurity: Whether the customer has an online security add-on (yes, no)\n",
    "* OnlineBackup: Whether the customer has an online backup add-on (yes, no)\n",
    "* DeviceProtection: Whether the customer has device protection add-on (yes, no)\n",
    "* TechSupport: Whether the customer has a technical support add-on (yes, no)\n",
    "* StreamingTV: Whether the customer has streaming TV (yes, no)\n",
    "* StreamingMovies: Whether the customer has streaming movies (yes, no)\n",
    "    \n",
    "<br>Finally, <b>discrete ordinal predictor variables</b> from the survey responses from customers regarding various customer service features may be relevant in the decision-making process. In the surveys, customers provided ordinal numerical data by rating 8 customer service factors on a scale of 1 to 8 (1 = most important, 8 = least important): \n",
    "    \n",
    "* Item1: Timely response\n",
    "* Item2: Timely fixes\n",
    "* Item3: Timely replacements\n",
    "* Item4: Reliability\n",
    "* Item5: Options\n",
    "* Item6: Respectful response\n",
    "* Item7: Courteous exchange\n",
    "* Item8: Evidence of active listening\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>C2. Summary Statistics</b>:</span>\n",
    "Discuss the summary statistics, including the target variable and all predictor variables that you will need to gather from the data set to answer the research question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>C3. Steps to Prepare Data</b>:</span>\n",
    "\n",
    "* Import dataset to Python dataframe.\n",
    "* Rename columns/variables of survey to easily recognizable features (ex: \"Item1\" to \"TimelyResponse\").\n",
    "* Get a description of dataframe, structure (columns & rows) & data types.\n",
    "* View summary statistics.\n",
    "* Drop less meaningful identifying (ex: \"Customer_id\") & demographic columns (ex: zip code) from dataframe.\n",
    "* Check for records with missing data & impute missing data with meaningful measures of central tendency (mean, median or mode) or simply remove outliers that are several standard deviations above the mean.\n",
    "* Create dummy variables in order to encoded categorical, yes/no data points into 1/0 numerical values.\n",
    "* View univariate & bivariate visualizations.\n",
    "* Place Bandwidth_GB_Year at end of dataframe\n",
    "* Finally, the prepared dataset will be extracted & provided as \"churn_prepared.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Increase Jupyter display cell-width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard data science imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "# Visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Statistics packages\n",
    "import pylab\n",
    "from pylab import rcParams\n",
    "import statsmodels.api as sm\n",
    "import statistics\n",
    "from scipy import stats\n",
    "\n",
    "# Scikit-learn\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Import chisquare from SciPy.stats\n",
    "from scipy.stats import chisquare\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Ignore Warning Code\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change color of Matplotlib font\n",
    "import matplotlib as mpl\n",
    "\n",
    "COLOR = 'white'\n",
    "mpl.rcParams['text.color'] = COLOR\n",
    "mpl.rcParams['axes.labelcolor'] = COLOR\n",
    "mpl.rcParams['xtick.color'] = COLOR\n",
    "mpl.rcParams['ytick.color'] = COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set into Pandas dataframe\n",
    "churn_df = pd.read_csv('Data/churn_clean.csv')\n",
    "\n",
    "# Rename last 8 survey columns for better description of variables\n",
    "churn_df.rename(columns = {'Item1':'TimelyResponse', \n",
    "                    'Item2':'Fixes', \n",
    "                     'Item3':'Replacements', \n",
    "                     'Item4':'Reliability', \n",
    "                     'Item5':'Options', \n",
    "                     'Item6':'Respectfulness', \n",
    "                     'Item7':'Courteous', \n",
    "                     'Item8':'Listening'}, \n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Churn dataframe\n",
    "churn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Dataframe Columns\n",
    "df = churn_df.columns\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of records and columns of dataset\n",
    "churn_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe Churn dataset statistics\n",
    "churn_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove less meaningful demographic variables from statistics description\n",
    "churn_df = churn_df.drop(columns=['CaseOrder', 'Customer_id', 'Interaction', 'UID', 'City', \n",
    "                            'State', 'County', 'Zip', 'Lat', 'Lng', 'Population', \n",
    "                            'Area', 'TimeZone', 'Job', 'Marital', 'PaymentMethod'])\n",
    "churn_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover missing data points within dataset\n",
    "data_nulls = churn_df.isnull().sum()\n",
    "print(data_nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy variable data preparation\n",
    "<span style=\"color:red\">Turn all yes/no into dummy variables a la Performance Lab Python</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df['DummyGender'] = [1 if v == 'Male' else 0 for v in churn_df['Gender']]\n",
    "churn_df['DummyChurn'] = [1 if v == 'Male' else 0 for v in churn_df['Churn']]\n",
    "churn_df['DummyTechie'] = [1 if v == 'Yes' else 0 for v in churn_df['Techie']]\n",
    "churn_df['DummyContract'] = [1 if v == 'Two Year' else 0 for v in churn_df['Contract']]\n",
    "churn_df['DummyPort_modem'] = [1 if v == 'Yes' else 0 for v in churn_df['Port_modem']]\n",
    "churn_df['DummyTablet'] = [1 if v == 'Yes' else 0 for v in churn_df['Tablet']]\n",
    "churn_df['DummyInternetService'] = [1 if v == 'Fiber Optic' else 0 for v in churn_df['InternetService']]\n",
    "churn_df['DummyPhone'] = [1 if v == 'Yes' else 0 for v in churn_df['Phone']]\n",
    "churn_df['DummyMultiple'] = [1 if v == 'Yes' else 0 for v in churn_df['Multiple']]\n",
    "churn_df['DummyOnlineSecurity'] = [1 if v == 'Yes' else 0 for v in churn_df['OnlineSecurity']]\n",
    "churn_df['DummyOnlineBackup'] = [1 if v == 'Yes' else 0 for v in churn_df['OnlineBackup']]\n",
    "churn_df['DummyDeviceProtection'] = [1 if v == 'Yes' else 0 for v in churn_df['DeviceProtection']]\n",
    "churn_df['DummyTechSupport'] = [1 if v == 'Yes' else 0 for v in churn_df['TechSupport']]\n",
    "churn_df['DummyStreamingTV'] = [1 if v == 'Yes' else 0 for v in churn_df['StreamingTV']]\n",
    "churn_df['StreamingMovies'] = [1 if v == 'Yes' else 0 for v in churn_df['StreamingMovies']]\n",
    "churn_df['DummyPaperlessBilling'] = [1 if v == 'Yes' else 0 for v in churn_df['PaperlessBilling']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original categorical features from dataframe\n",
    "churn_df = churn_df.drop(columns=['Gender', 'Churn', 'Techie', 'Contract', 'Port_modem', 'Tablet', \n",
    "                                  'InternetService', 'Phone', 'Multiple', 'OnlineSecurity', \n",
    "                                  'OnlineBackup', 'DeviceProtection', 'TechSupport', \n",
    "                                  'StreamingTV', 'StreamingMovies', 'PaperlessBilling'])\n",
    "churn_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = churn_df.columns\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move Bandwidth_GB_Year to end of dataset as target\n",
    "churn_df = churn_df[['Children', 'Age', 'Income', 'Outage_sec_perweek', 'Email', 'Contacts',\n",
    "       'Yearly_equip_failure', 'Tenure', 'MonthlyCharge', \n",
    "        'TimelyResponse', 'Fixes', 'Replacements',\n",
    "       'Reliability', 'Options', 'Respectfulness', 'Courteous', 'Listening',\n",
    "       'DummyGender', 'DummyChurn', 'DummyTechie', 'DummyContract',\n",
    "       'DummyPort_modem', 'DummyTablet', 'DummyInternetService', 'DummyPhone',\n",
    "       'DummyMultiple', 'DummyOnlineSecurity', 'DummyOnlineBackup',\n",
    "       'DummyDeviceProtection', 'DummyTechSupport', 'DummyStreamingTV',\n",
    "       'DummyPaperlessBilling', 'Bandwidth_GB_Year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = churn_df.columns\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>C4. Visualizations</b>:</span>\n",
    "Generate univariate and bivariate visualizations of the distributions of variables in the cleaned data set. Include the target variable in your bivariate visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values in dataset\n",
    "\n",
    "# Install appropriate library\n",
    "!pip install missingno\n",
    "\n",
    "# Importing the libraries\n",
    "import missingno as msno\n",
    "\n",
    "# Visualize missing values as a matrix\n",
    "msno.matrix(churn_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''No need to impute an missing values as the dataset appears complete/cleaned'''\n",
    "# Impute missing fields for variables Children, Age, Income, Tenure and Bandwidth_GB_Year with median or mean\n",
    "# churn_df['Children'] = churn_df['Children'].fillna(churn_df['Children'].median())\n",
    "# churn_df['Age'] = churn_df['Age'].fillna(churn_df['Age'].median())\n",
    "# churn_df['Income'] = churn_df['Income'].fillna(churn_df['Income'].median())\n",
    "# churn_df['Tenure'] = churn_df['Tenure'].fillna(churn_df['Tenure'].median())\n",
    "# churn_df['Bandwidth_GB_Year'] = churn_df['Bandwidth_GB_Year'].fillna(churn_df['Bandwidth_GB_Year'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create histograms of contiuous variables\n",
    "churn_df[['Children', 'Age', 'Income', 'Outage_sec_perweek', 'Email', \n",
    "          'Contacts', 'Yearly_equip_failure', 'Tenure', 'MonthlyCharge', \n",
    "          'Bandwidth_GB_Year']].hist()\n",
    "plt.savefig('churn_pyplot.jpg')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Seaborn boxplots for continuous variables\n",
    "sns.boxplot('Tenure', data = churn_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot('MonthlyCharge', data = churn_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot('Bandwidth_GB_Year', data = churn_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It appears that anomolies have been removed from the dataset present \"churn_clean.csv\" as there are no remaining outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's run some scatterplots to get an idea of our linear relationships with our target variable of \"Bandwidth_GB_Year\" usage & some of the respective predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run scatterplots to show direct or inverse relationships between target & independent variables\n",
    "sns.scatterplot(x=churn_df['Children'], y=churn_df['Bandwidth_GB_Year'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=churn_df['Age'], y=churn_df['Bandwidth_GB_Year'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=churn_df['Income'], y=churn_df['Bandwidth_GB_Year'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=churn_df['Outage_sec_perweek'], y=churn_df['Bandwidth_GB_Year'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=churn_df['Email'], y=churn_df['Bandwidth_GB_Year'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=churn_df['Contacts'], y=churn_df['Bandwidth_GB_Year'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=churn_df['Yearly_equip_failure'], y=churn_df['Bandwidth_GB_Year'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=churn_df['Tenure'], y=churn_df['Bandwidth_GB_Year'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=churn_df['MonthlyCharge'], y=churn_df['Bandwidth_GB_Year'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=churn_df['TimelyResponse'], y=churn_df['Bandwidth_GB_Year'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=churn_df['Fixes'], y=churn_df['Bandwidth_GB_Year'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=churn_df['DummyTechie'], y=churn_df['Bandwidth_GB_Year'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>C5. Prepared Dataset</b>:</span>\n",
    "Provide a copy of the prepared data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Clean dataset\n",
    "churn_df.to_csv('data/churn_prepared.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>D1. Initial Model</b></span>\n",
    "Construct an initial multiple regression model from <span style=\"color:red\"><i>all predictors that were identified in Part C2</i></span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Develop the initial estimated regression equation that could be used to predict the Bandwidth_GB_Year, given the only continuous variables\"\"\"\n",
    "churn_df['intercept'] = 1\n",
    "lm_bandwidth = sm.OLS(churn_df['Bandwidth_GB_Year'], churn_df[['Children', 'Age', \n",
    "                                                               'Income',\n",
    "                                                               'Outage_sec_perweek', \n",
    "                                                               'Email', 'Contacts',\n",
    "                                                               'Yearly_equip_failure', \n",
    "                                                               'Tenure', 'MonthlyCharge', \n",
    "                                                               'TimelyResponse', 'Fixes', \n",
    "                                                               'Replacements', 'Reliability', \n",
    "                                                               'Options', 'Respectfulness', \n",
    "                                                               'Courteous', 'Listening', \n",
    "                                                               'intercept']]).fit()\n",
    "print(lm_bandwidth.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df_dummies = churn_df.columns\n",
    "print(churn_df_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's run a model including all encoded categorical dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Model including all dummy variables\"\"\"\n",
    "churn_df['intercept'] = 1\n",
    "lm_bandwidth = sm.OLS(churn_df['Bandwidth_GB_Year'], churn_df[['Children', 'Age', \n",
    "                                                               'Income', 'Outage_sec_perweek', \n",
    "                                                               'Email', 'Contacts',\n",
    "                                                               'Yearly_equip_failure', \n",
    "                                                               'DummyTechie', 'DummyContract', \n",
    "                                                               'DummyPort_modem', 'DummyTablet', \n",
    "                                                               'DummyInternetService', 'DummyPhone', \n",
    "                                                               'DummyMultiple', 'DummyOnlineSecurity', \n",
    "                                                               'DummyOnlineBackup', 'DummyDeviceProtection', \n",
    "                                                               'DummyTechSupport', 'DummyStreamingTV', \n",
    "                                                               'DummyPaperlessBilling',\n",
    "                                                               'Tenure', 'MonthlyCharge', \n",
    "                                                               'TimelyResponse', 'Fixes', \n",
    "                                                               'Replacements', 'Reliability', \n",
    "                                                               'Options', 'Respectfulness', \n",
    "                                                               'Courteous', 'Listening', \n",
    "                                                               'intercept']]).fit()\n",
    "print(lm_bandwidth.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Multiple Linear Regression Model\n",
    "With <b><i>30</i></b> indpendent variables (17 continuous & 13 categorical): \n",
    "<br><br>&emsp;<span style=\"color:gold\">y = 104.85 + 30.86 * Children - 3.31 * Age + 0.00 * Income - 0.26 * Outage_sec_perweek - 0.31 * Email + 2.95 * Contacts + 0.67 * Yearly_equip_failure + 0.62 * DummyTechie + 3.93 * DummyContract + 0.47 * DummyPort_modem - 1.98 * DummyTablet - 373.71 * DummyInternetService - 2.15 * DummyPhone - 76.08 * DummyMultiple + 67.49 * DummyOnlineSecurity - 12.66 * DummyOnlineBackup + 24.89 * DummyDeviceProtection - 52.58 * DummyTechSupport + 30.48 * DummyStreamingTV - 2.64 * DummyPaperlessBilling + 82.01 * Tenure + 3.28 * MonthlyCharge - 8.9 * TimelyResponse + 3.47 * Fixes - 0.18 * Replacements - 0.27 * Reliability + 2.72 * Options + 1.72 * Respectfulness - 1.35 * Courteous + 5.78 * Listening</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on an R<sup>2</sup> value = 0.989.  So, 99% of the variation is explained by this model.  The condition number is large which might suggest strong multicolinnearity.  Apparently, we do not need all of these variables to explain the variance.  So, let's run a heatmap for bivariate analysis & a principal component analysis in order to reduce variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>D2. Justification of Model Reduction</b></span>\n",
    "Justify a statistically based variable selection procedure and a model evaluation metric to reduce the initial model in a way that aligns with the research question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for heatmap bivariate analysis of correlation\n",
    "churn_bivariate = churn_df[['Bandwidth_GB_Year', 'Children', 'Age', 'Income', \n",
    "                            'Outage_sec_perweek', 'Yearly_equip_failure', 'DummyTechie', 'DummyContract', \n",
    "                            'DummyPort_modem', 'DummyTablet', 'DummyInternetService', \n",
    "                            'DummyPhone', 'DummyMultiple', 'DummyOnlineSecurity', \n",
    "                            'DummyOnlineBackup', 'DummyDeviceProtection', \n",
    "                            'DummyTechSupport', 'DummyStreamingTV', \n",
    "                            'DummyPaperlessBilling','Email', 'Contacts',  \n",
    "                            'Tenure', 'MonthlyCharge', 'TimelyResponse', 'Fixes', \n",
    "                            'Replacements', 'Reliability', 'Options', 'Respectfulness', \n",
    "                            'Courteous', 'Listening']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run Seaborn heatmap\n",
    "sns.heatmap(churn_bivariate.corr(), annot=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alrighty, let's try that without some demographic, contacting-customer & options variables, basically purple or darker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_bivariate = churn_df[['Bandwidth_GB_Year', 'Children',\n",
    "                            'Tenure', 'TimelyResponse', 'Fixes', \n",
    "                            'Replacements', 'Respectfulness', \n",
    "                            'Courteous', 'Listening']]\n",
    "\n",
    "sns.heatmap(churn_bivariate.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That looks a lot better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Again, it appears that Tenure is the predictor for most of the variance.  There is clearly a direct linear relationship between customer tenure with the telecom company & the amount of data (in GBs) that is being used.  Let's run a multiple linear regression model on those variables with 0.50 or above & children because of its high coefficient (30.86) on the original OLS model. I also add children intuitively because children always add cost & using the p-value for children is 0.000, & therefore statistically significant.  \n",
    "### So, the reduced regression equation will include the continuous variable of tenure & the categorical of children as well ad the the ordinal categorical independent variables of fixes & replacements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>D3. Reduced Multiple Regression Model</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run reduced OLS multiple regression\n",
    "churn_df['intercept'] = 1\n",
    "lm_bandwidth_reduced = sm.OLS(churn_df['Bandwidth_GB_Year'], churn_df[['Children', 'Tenure', 'Fixes', 'Replacements', 'intercept']]).fit()\n",
    "print(lm_bandwidth_reduced.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well, there it is.  Removing all those other predictor variables & our model still explains 98% of the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced Multiple Linear Regression Model\n",
    "With <b>4</b> indpendent variables: \n",
    "<br><br>&emsp;<span style=\"color:gold\">y = 497.78 + 31.18 * Children + 81.94 * Tenure + 1.07 * Fixes - 3.66 * Replacements</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>E1. Model Comparison</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5fcc6f76a79e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchurn_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/churn_prepared.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mresiduals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchurn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Bandwidth_GB_Year'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlm_bandwidth_reduced\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchurn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Children'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Tenure'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Fixes'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Replacements'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'intercept'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchurn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tenure'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresiduals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'red'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "churn_df = pd.read_csv('data/churn_prepared.csv')\n",
    "\n",
    "residuals = churn_df['Bandwidth_GB_Year'] - lm_bandwidth_reduced.predict(churn_df[['Children', 'Tenure', 'Fixes', 'Replacements','intercept']])\n",
    "sns.scatterplot(x=churn_df['Tenure'],y=residuals,color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>E2. Output & Calculations</b></span>\n",
    "Provide the output and any calculations of the analysis you performed, including the modelâ€™s residual error.\n",
    "\n",
    "\n",
    "\n",
    "<span style='color:red'>Note: The output should include the predictions from the refined model you used to perform the analysis. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>E3. Code</b></span>\n",
    "All code for analysis include above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:Gold'><b>Part V: Data Summary and Implications</b></span>\n",
    "\n",
    "F.  Summarize your findings and assumptions by doing the following:\n",
    "\n",
    "1.  Discuss the results of your data analysis, including the following elements:\n",
    "<ul>\n",
    "    <li>\n",
    "    a regression equation for the reduced model\n",
    "    </li>\n",
    "    <li>\n",
    "    an interpretation of coefficients of the statistically significant variables of the model\n",
    "    </li>\n",
    "    <li>\n",
    "    the statistical and practical significance of the model\n",
    "    </li>\n",
    "    <li>\n",
    "    the limitations of the data analysis\n",
    "    </li>\n",
    "</ul>\n",
    "2.  Recommend a course of action based on your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>F1. Results</b></span>\n",
    " Discuss the results of your data analysis, including the following elements:\n",
    "<ul>\n",
    "    <li>\n",
    "    The final multiple regression equation with <b>4</b> indpendent variables: \n",
    "<br>&emsp;<span style=\"color:gold\">y = 497.78 + 31.18 * Children + 81.94 * Tenure + 1.07 * Fixes - 3.66 * Replacements</span><br>\n",
    "    </li>\n",
    "    <li>\n",
    "    The coefficients suggest that for every 1 unit of:\n",
    "        <ul>\n",
    "            <li>Children - Bandwidth_GB_Year will increase 31.18 units</li>\n",
    "            <li>Tenure - Bandwidth_GB_Year will increase 81.94 units</li>\n",
    "            <li>Fixes - Bandwidth_GB_Year will increase 1.07 units</li>\n",
    "            <li>Replacements -  - Bandwidth_GB_Year will decrease 3.66 units</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "    P-values for Children & Tenure are statistically significant at 0.000, while p-values for Fixes & Replacements are not statistically significant at 0.73 & 0.25, respectively.\n",
    "    </li>\n",
    "    <li>\n",
    "    The limitations of this analysis are that the data set is a bit small & that perhaps more years of data need to be collected.  Also, correlation is not causation so we cannot tell whether longer tenure with the company causes higher yearly bandwith usage or vice versa or if there is another variable that causes both.  More investigation is required.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>F2. Recommendations</b></span>\n",
    "For the purposes of this analysis & to make the time spent on the analysis acceptable & provide actionable information:  \n",
    "with such a direct linear relationship between bandwidth used yearly & tenure with the telecom company it makes sense to suggest the company do everything within marketing & customer service capability to retain the customers gained as the longer they stay with the company the more bandwidth they tend to use.  This would include making sure that fixes to customer problems are prompt & that the equipment provided is high quality to avoid fewer replacements of equipment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>G. Video</b></span>\n",
    "<span style=\"color:red\">link</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">H. Sources for Third-Party Code</span>\n",
    "\n",
    "Kaggle. (2018, May 01). Bivariate plotting with pandas. Kaggle. https://www.kaggle.com/residentmario/bivariate-plotting-with-pandas#\n",
    "\n",
    "<br> Sree. &ensp; (2020, October 26). &ensp; <i>Predict Customer Churn in Python.</i> &ensp; Towards Data Science. https://towardsdatascience.com/predict-customer-churn-in-python-e8cd6d3aaa7\n",
    "\n",
    "<br> Wikipedia. (2021, May 31). Bivariate Analysis. https://en.wikipedia.org/wiki/Bivariate_analysis#:~:text=Bivariate%20analysis%20is%20one%20of,the%20empirical%20relationship%20between%20them.&text=Like%20univariate%20analysis%2C%20bivariate%20analysis%20can%20be%20descriptive%20or%20inferential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">I. Sources</span>\n",
    "\n",
    "Ahmad, A. K., Jafar, A & Aljoumaa, K. &ensp; (2019, March 20). &ensp; <i>Customer churn prediction in telecom using machine learning in big data platform</i>. &ensp; Journal of Big Data. https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0191-6\n",
    "\n",
    "<br> Altexsoft. &ensp; (2019, March 27). &ensp; <i>Customer Churn Prediction Using Machine Learning: Main Approaches and Models</i>. &ensp; Altexsoft. &ensp; &ensp; https://www.altexsoft.com/blog/business/customer-churn-prediction-for-subscription-businesses-using-machine-learning-main-approaches-and-models/\n",
    "\n",
    "<br> Bruce, P., Bruce A. & Gedeck P. &ensp; (2020). &ensp; <i>Practical Statistics for Data Scientists</i>. &ensp; O'Reilly.\n",
    "\n",
    "<br> CBTNuggets. &ensp; (2018, September 20). &ensp; <i>Why Data Scientists Love Python</i>. &ensp; https://www.cbtnuggets.com/blog/technology/data/why-data-scientists-love-python\n",
    "\n",
    "<br> Freedman, D. Pisani, R. & Purves, R. &ensp; (2018). &ensp; <i>Statistics</i>. &ensp; W. W. Norton & Company, Inc. \n",
    "\n",
    "<br> Frohbose, F. &ensp; (2020, November 24). &ensp; <i>Machine Learning Case Study: Telco Customer Churn Prediction</i>.  &ensp; Towards Data Science. &ensp; https://towardsdatascience.com/machine-learning-case-study-telco-customer-churn-prediction-bc4be03c9e1d\n",
    "\n",
    "<br> Griffiths, D. &ensp; (2009). &ensp; <i>A Brain-Friendly Guide: Head First Statistics</i>. &ensp; O'Reilly.\n",
    "\n",
    "<br> Grus, J. &ensp; (2015). &ensp; <i>Data Science from Scratch</i>. &ensp; O'Reilly.\n",
    "\n",
    "<br> Massaron, L. & Boschetti, A. &ensp; (2016). &ensp; <i>Regression Analysis with Python</i>. &ensp; Packt Publishing.\n",
    "\n",
    "<br> McKinney, W. &ensp; (2018). &ensp; <i>Python for Data Analysis</i>. O'Reilly.\n",
    "\n",
    "<br> Rossant, C. (2018). &ensp; <i>IPython Interactive Computing & Visualization Cookbook, 2nd Edition</i>. &ensp; Packt Publishing.\n",
    "\n",
    "<br> Rossant, C. (2015). &ensp; <i>Learning IPython Interactive Computing & Visualization, 2nd Edition</i>. &ensp; Packt Publishing.\n",
    "\n",
    "<br> VanderPlas, J. &ensp; (2017). &ensp; <i>Python Data Science Handbook</i>. &ensp; O'Reilly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/brpy/colab-pdf/master/colab_pdf.py\n",
    "from colab_pdf import colab_pdf\n",
    "colab_pdf('D208_Performance_Assessment_NBM2_Task_1.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
