{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "D208_Performance_Assessment_NBM2_Task_2_revision.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "P6SkIoP6vv2P",
        "kdQySbqPvv2T",
        "OhgbyCsjvv2T",
        "c6dbaaJjvv2T",
        "sS7m0Hskvv2T",
        "S3-6KZOIvv2T",
        "zoPUh7e2vv2U",
        "Nja8VkdAvv2U",
        "NT4TS9uxvv2U",
        "-OjZoiaxvv2U",
        "t7xqLWrXvv2V",
        "sf89bOWnvv2V"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAlIxlCovv1-"
      },
      "source": [
        "# <span style=\"color:turquoise\">D208 Performance Assessment NBM2 Task 2</span>\n",
        "## <span style=\"color:turquoise\">Logistic Regression for Predictive Modeling</span>\n",
        "&emsp;Ryan L. Buchanan\n",
        "<br>&emsp;Student ID:  001826691\n",
        "<br>&emsp;Masters Data Analytics (12/01/2020)\n",
        "<br>&emsp;Program Mentor:  Dan Estes\n",
        "<br>&emsp;(385) 432-9281 (MST)\n",
        "<br>&emsp;rbuch49@wgu.edu\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFEmnRMHvv2B"
      },
      "source": [
        "### <span style=\"color:green\"><b>A1. Research Question</b>:</span>\n",
        "Can we determine which individual customers are at high risk of churn? &nbsp; And, can we determine which features are most significant to churn?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_LdtRqfvv2C"
      },
      "source": [
        "### <span style=\"color:green\"><b>A2. Objectives & Goals</b>:</span>\n",
        "&emsp; Stakeholders in the company will benefit by knowing, with some measure of confidence, which customers are likely to churn soon. &nbsp; This knowledge will provide weight for decisions in marketing improved services to customers with these characteristics & past user experiences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeRqzSlKvv2C"
      },
      "source": [
        "### <span style=\"color:green\"><b>B1. Summary of Assumptions</b>:</span>\n",
        "Assumptions of a logistic regression model include:\n",
        "* It is based on Bernoulli (also, Binomial or Boolean) Distribution rather than Gaussian because the dependent variable is binary (in our dataset, to churn or not to churn).\n",
        "* The predicted values are restricted to a range of nomial values: \"Yes\" or \"No.\"\n",
        "* It predicts the probability of a particular outcome rather than the outcome itself.\n",
        "* There are no high correlations (multicollinearity) among predictors.\n",
        "* It is the logarithm of the odds of achieving 1. &nbsp; In other words, a regression model, where the output is natural logarithm of the odds, also known as 'logit'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYZPSPTNvv2D"
      },
      "source": [
        "### <span style=\"color:green\"><b>B2. Tool Benefits</b>:</span>\n",
        "&emsp; Python & IPython Jupyter notebooks will be used to support this analysis. &nbsp; Python offers an intuitive, simple & versatile programming style & syntax, as well as a large system of mature packages for data science & machine learning. &nbsp; Since, Python is cross-platform, it will work well whether consumers of the analysis are using Windows PCs or a MacBook laptop. &nbsp; It is fast when compared with other possible programming languages like R or MATLAB <span style=\"color:red\">(Massaron, p. 8)</span>.\n",
        "<br> &emsp; Also, there is strong support for Python as the most popular data science programming language in popular literature & media <span style=\"color:red\">(CBTNuggets, p. 1)</span>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhdbzMK8vv2D"
      },
      "source": [
        "### <span style=\"color:green\"><b>B3. Appropriate Technique</b>:</span>\n",
        "&emsp; Logistic regression is an appropriate technique to analyze the research question because or dependent variable is binomial, Yes or No. &nbsp; We want to find out what the likelihood of customer churn is for individual customers, based on a list of independent variables (area type, job, children, age, income, etc.). &nbsp; It will improve our understanding of increased probability of churn as we include or remove different independent variables & find out whether or not they have a positive or negative relationship to our target variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgyu1E0Avv2E"
      },
      "source": [
        "### <span style=\"color:green\"><b>C1. Data Goals</b>:</span>\n",
        "\n",
        "My approach will include:\n",
        "<br>&ensp; 1. Back up my data and the process I am following as a copy to my machine and, since this is a manageable dataset, to GitHub using command line and gitbash.\n",
        "<br>&ensp; 2. Read the data set into Python using Pandas' read_csv command.\n",
        "<br>&ensp; 3. Evaluate the data struture to better understand input data.\n",
        "<br>&ensp; 4. Naming the dataset as a the variable \"churn_df\" and subsequent useful slices of the dataframe as \"df\".\n",
        "<br>&ensp; 5. Examine potential misspellings, awkward variable naming & missing data.\n",
        "<br>&ensp; 6. Find outliers that may create or hide statistical significance using histograms.\n",
        "<br>&ensp; 7. Imputing records missing data with meaningful measures of central tendency (mean, median or mode) or simply remove outliers that are several standard deviations above the mean.\n",
        "\n",
        "&emsp; Most relevant to our decision making process is the <b>dependent variable</b> of \"Churn\" which is binary categorical with only two values, Yes or No.  Churn will be our <b>categorical target variable</b>. \n",
        "\n",
        "<br>In cleaning the data, we may discover relevance of the <b>continuous predictor variables</b>: \n",
        "\n",
        "* Children\n",
        "* Income\n",
        "* Outage_sec_perweek\n",
        "* Email\n",
        "* Contacts    \n",
        "* Yearly_equip_failure\n",
        "* Tenure (the number of months the customer has stayed with the provider)\n",
        "* MonthlyCharge\n",
        "* Bandwidth_GB_Year    \n",
        "    \n",
        "<br>&emsp; Likewise, we may discover relevance of the <b>categorical predictor variables</b> (all binary categorical with only two values, Yes or No, except where noted): \n",
        "\n",
        "* Techie: Whether the customer considers themselves technically inclined (based on customer questionnaire when they signed up for services) (yes, no)\n",
        "* Contract: The contract term of the customer (month-to-month, one year, two year)\n",
        "* Port_modem: Whether the customer has a portable modem (yes, no)\n",
        "* Tablet: Whether the customer owns a tablet such as iPad, Surface, etc. (yes, no)\n",
        "* InternetService: Customerâ€™s internet service provider (DSL, fiber optic, None)\n",
        "* Phone: Whether the customer has a phone service (yes, no)\n",
        "* Multiple: Whether the customer has multiple lines (yes, no)\n",
        "* OnlineSecurity: Whether the customer has an online security add-on (yes, no)\n",
        "* OnlineBackup: Whether the customer has an online backup add-on (yes, no)\n",
        "* DeviceProtection: Whether the customer has device protection add-on (yes, no)\n",
        "* TechSupport: Whether the customer has a technical support add-on (yes, no)\n",
        "* StreamingTV: Whether the customer has streaming TV (yes, no)\n",
        "* StreamingMovies: Whether the customer has streaming movies (yes, no)\n",
        "    \n",
        "<br>&emsp; Finally, <b>discrete ordinal predictor variables</b> from the survey responses from customers regarding various customer service features may be relevant in the decision-making process. &nbsp; In the surveys, customers provided ordinal numerical data by rating 8 customer service factors on a scale of 1 to 8 (1 = most important, 8 = least important): \n",
        "    \n",
        "* Item1: Timely response\n",
        "* Item2: Timely fixes\n",
        "* Item3: Timely replacements\n",
        "* Item4: Reliability\n",
        "* Item5: Options\n",
        "* Item6: Respectful response\n",
        "* Item7: Courteous exchange\n",
        "* Item8: Evidence of active listening\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc0M2lrXvv2F"
      },
      "source": [
        "### <span style=\"color:green\"><b>C2. Summary Statistics</b>:</span>\n",
        "&emsp; As output by Python pandas dataframe methods below, the dataset consists of 50 original columns & 10,000 records. &nbsp; For purposes of this analysis certain user ID & demographic categorical variables (CaseOrder, Customer_id, Interaction, UID, City, State, County, Zip, Lat, Lng, Population, Area, TimeZone, Job, Marital, PaymentMethod) were removed from the dataframe. &nbsp; Also, binomial Yes/No or Male/Female, variables were encoded to 1/0, respectively. &nbsp; This resulted in 34 remaining numerical variables, including the target variable. &nbsp; The dataset appeared to be sufficiently cleaned leaving no null, NAs or missing data points.\n",
        "<br> &emsp; Measures of central tendency through histograms & boxplots revealed normal distributions for Monthly_Charge, Outage_sec_perweek & Email. &nbsp; The cleaned dataset no longer retained any outliers. &nbsp; Histograms for Bandwidth_GB_Year & Tenure displayed bimodal distributions, which demonstrated a direct linear relationship with each other in a scatterplot. &nbsp; The average customer was 53 years-old (with a standard deviation of 20 years), had 2 children  (with a standard deviation of 2 kids), an income of 39,806 (with a standard deviation of about 30,000), experienced 10 outage-seconds/week, was marketed to by email 12 times, contacted technical support less than one time, had less than 1 yearly equipment failure, has been with the company for 34.5 months, has a monthly charge of approximately 173 & uses 3,392 GBs/year."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp3pVTGAvv2G"
      },
      "source": [
        "### <span style=\"color:green\"><b>C3. Steps to Prepare Data</b>:</span>\n",
        "\n",
        "* Import dataset to Python dataframe.\n",
        "* Rename columns/variables of survey to easily recognizable features (ex: \"Item1\" to \"TimelyResponse\").\n",
        "* Get a description of dataframe, structure (columns & rows) & data types.\n",
        "* View summary statistics.\n",
        "* Drop less meaningful identifying (ex: \"Customer_id\") & demographic columns (ex: zip code) from dataframe.\n",
        "* Check for records with missing data & impute missing data with meaningful measures of central tendency (mean, median or mode) or simply remove outliers that are several standard deviations above the mean.\n",
        "* Create dummy variables in order to encode categorical, yes/no data points into 1/0 numerical values.\n",
        "* View univariate & bivariate visualizations.\n",
        "* Place \"Churn\" at end of dataframe\n",
        "* Finally, the prepared dataset will be extracted & provided as \"churn_prepared_log.csv\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liiPXy2rvv2I"
      },
      "source": [
        "# Increase Jupyter display cell-width\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIOCYY4gvv2J"
      },
      "source": [
        "# Standard data science imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import Series, DataFrame\n",
        "\n",
        "# Visualization libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Statistics packages\n",
        "import pylab\n",
        "from pylab import rcParams\n",
        "import statsmodels.api as sm\n",
        "import statistics\n",
        "from scipy import stats\n",
        "\n",
        "# Scikit-learn\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "# Import chisquare from SciPy.stats\n",
        "from scipy.stats import chisquare\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Ignore Warning Code\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDXGToLdvv2J"
      },
      "source": [
        "# Change color of Matplotlib font\n",
        "import matplotlib as mpl\n",
        "\n",
        "COLOR = 'white'\n",
        "mpl.rcParams['text.color'] = COLOR\n",
        "mpl.rcParams['axes.labelcolor'] = COLOR\n",
        "mpl.rcParams['xtick.color'] = COLOR\n",
        "mpl.rcParams['ytick.color'] = COLOR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JUI-7w3vv2K"
      },
      "source": [
        "# Load data set into Pandas dataframe\n",
        "churn_df = pd.read_csv('Data/churn_clean.csv')\n",
        "\n",
        "# Rename last 8 survey columns for better description of variables\n",
        "churn_df.rename(columns = {'Item1':'TimelyResponse', \n",
        "                    'Item2':'Fixes', \n",
        "                     'Item3':'Replacements', \n",
        "                     'Item4':'Reliability', \n",
        "                     'Item5':'Options', \n",
        "                     'Item6':'Respectfulness', \n",
        "                     'Item7':'Courteous', \n",
        "                     'Item8':'Listening'}, \n",
        "          inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kEs2qRqvv2K"
      },
      "source": [
        "# Display Churn dataframe\n",
        "churn_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5piV9Vavv2K"
      },
      "source": [
        "# List of Dataframe Columns\n",
        "df = churn_df.columns\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me4_2Gclvv2L"
      },
      "source": [
        "# Find number of records and columns of dataset\n",
        "churn_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OJKbpgnvv2L"
      },
      "source": [
        "# Describe Churn dataset statistics\n",
        "churn_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP-QgrM8vv2L"
      },
      "source": [
        "# Remove less meaningful demographic variables from statistics description\n",
        "churn_df = churn_df.drop(columns=['CaseOrder', 'Customer_id', 'Interaction', 'UID', 'City', \n",
        "                            'State', 'County', 'Zip', 'Lat', 'Lng', 'Population', \n",
        "                            'Area', 'TimeZone', 'Job', 'Marital', 'PaymentMethod'])\n",
        "churn_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnvwnCASvv2L"
      },
      "source": [
        "# Discover missing data points within dataset\n",
        "data_nulls = churn_df.isnull().sum()\n",
        "print(data_nulls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X18frVHlvv2M"
      },
      "source": [
        "### Dummy variable data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuAR9IDfvv2M"
      },
      "source": [
        "churn_df['DummyGender'] = [1 if v == 'Male' else 0 for v in churn_df['Gender']]\n",
        "churn_df['DummyChurn'] = [1 if v == 'Yes' else 0 for v in churn_df['Churn']] ### If the customer left (churned) they get a '1'\n",
        "churn_df['DummyTechie'] = [1 if v == 'Yes' else 0 for v in churn_df['Techie']]\n",
        "churn_df['DummyContract'] = [1 if v == 'Two Year' else 0 for v in churn_df['Contract']]\n",
        "churn_df['DummyPort_modem'] = [1 if v == 'Yes' else 0 for v in churn_df['Port_modem']]\n",
        "churn_df['DummyTablet'] = [1 if v == 'Yes' else 0 for v in churn_df['Tablet']]\n",
        "churn_df['DummyInternetService'] = [1 if v == 'Fiber Optic' else 0 for v in churn_df['InternetService']]\n",
        "churn_df['DummyPhone'] = [1 if v == 'Yes' else 0 for v in churn_df['Phone']]\n",
        "churn_df['DummyMultiple'] = [1 if v == 'Yes' else 0 for v in churn_df['Multiple']]\n",
        "churn_df['DummyOnlineSecurity'] = [1 if v == 'Yes' else 0 for v in churn_df['OnlineSecurity']]\n",
        "churn_df['DummyOnlineBackup'] = [1 if v == 'Yes' else 0 for v in churn_df['OnlineBackup']]\n",
        "churn_df['DummyDeviceProtection'] = [1 if v == 'Yes' else 0 for v in churn_df['DeviceProtection']]\n",
        "churn_df['DummyTechSupport'] = [1 if v == 'Yes' else 0 for v in churn_df['TechSupport']]\n",
        "churn_df['DummyStreamingTV'] = [1 if v == 'Yes' else 0 for v in churn_df['StreamingTV']]\n",
        "churn_df['StreamingMovies'] = [1 if v == 'Yes' else 0 for v in churn_df['StreamingMovies']]\n",
        "churn_df['DummyPaperlessBilling'] = [1 if v == 'Yes' else 0 for v in churn_df['PaperlessBilling']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "j3aiMEk8vv2M"
      },
      "source": [
        "churn_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64gTDUmSvv2M"
      },
      "source": [
        "# Drop original categorical features from dataframe\n",
        "churn_df = churn_df.drop(columns=['Gender', 'Churn', 'Techie', 'Contract', 'Port_modem', 'Tablet', \n",
        "                                  'InternetService', 'Phone', 'Multiple', 'OnlineSecurity', \n",
        "                                  'OnlineBackup', 'DeviceProtection', 'TechSupport', \n",
        "                                  'StreamingTV', 'StreamingMovies', 'PaperlessBilling'])\n",
        "churn_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0BFZhjtvv2N"
      },
      "source": [
        "df = churn_df.columns\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-j8XVwMvv2N"
      },
      "source": [
        "# Move DummyChurn to end of dataset as target\n",
        "churn_df = churn_df[['Children', 'Age', 'Income', 'Outage_sec_perweek', 'Email', 'Contacts',\n",
        "       'Yearly_equip_failure', 'Tenure', 'MonthlyCharge', 'Bandwidth_GB_Year', \n",
        "        'TimelyResponse', 'Fixes', 'Replacements',\n",
        "       'Reliability', 'Options', 'Respectfulness', 'Courteous', 'Listening',\n",
        "       'DummyGender', 'DummyTechie', 'DummyContract',\n",
        "       'DummyPort_modem', 'DummyTablet', 'DummyInternetService', 'DummyPhone',\n",
        "       'DummyMultiple', 'DummyOnlineSecurity', 'DummyOnlineBackup',\n",
        "       'DummyDeviceProtection', 'DummyTechSupport', 'DummyStreamingTV',\n",
        "       'DummyPaperlessBilling', 'DummyChurn']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ee4BxjFFvv2N"
      },
      "source": [
        "df = churn_df.columns\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW_XFVRivv2N"
      },
      "source": [
        "### <span style=\"color:green\"><b>C4. Visualizations</b>:</span>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1w6-Jmnvv2N"
      },
      "source": [
        "# Visualize missing values in dataset\n",
        "\n",
        "# Install appropriate library\n",
        "!pip install missingno\n",
        "\n",
        "# Importing the libraries\n",
        "import missingno as msno\n",
        "\n",
        "# Visualize missing values as a matrix\n",
        "msno.matrix(churn_df);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4gNa7kQvv2O"
      },
      "source": [
        "## Univariate Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "22_smbY8vv2O"
      },
      "source": [
        "# Create histograms of contiuous variables\n",
        "churn_df[['Children', 'Age', 'Income', 'Outage_sec_perweek', 'Email', \n",
        "          'Contacts', 'Yearly_equip_failure', 'Tenure', 'MonthlyCharge', \n",
        "          'Bandwidth_GB_Year']].hist()\n",
        "plt.savefig('churn_pyplot.jpg')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCnHW_hUvv2O"
      },
      "source": [
        "# Create Seaborn boxplots for continuous variables\n",
        "sns.boxplot('Tenure', data = churn_df)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIyquiI_vv2O"
      },
      "source": [
        "sns.boxplot('MonthlyCharge', data = churn_df)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P45OBWt5vv2P"
      },
      "source": [
        "sns.boxplot('Bandwidth_GB_Year', data = churn_df)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6SkIoP6vv2P"
      },
      "source": [
        "## Anomalies\n",
        "### &emsp; It appears that anomolies have been removed from the supplied dataset, churn_clean.csv. &nbsp; There are no remaining outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dhrNb8Wvv2P"
      },
      "source": [
        "## Bivariate Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxSBtsD2vv2P"
      },
      "source": [
        "# Run scatterplots to show direct or inverse relationships between target & independent variables\n",
        "sns.scatterplot(x=churn_df['Children'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "w4r--Vuavv2P"
      },
      "source": [
        "sns.scatterplot(x=churn_df['Age'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGf1_x9ovv2P"
      },
      "source": [
        "sns.scatterplot(x=churn_df['Income'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j0XDOlXvv2P"
      },
      "source": [
        "sns.scatterplot(x=churn_df['DummyGender'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbG5KytLvv2Q"
      },
      "source": [
        "sns.scatterplot(x=churn_df['Outage_sec_perweek'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O68YoqRRvv2Q"
      },
      "source": [
        "sns.scatterplot(x=churn_df['Email'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZPATLbMvv2Q"
      },
      "source": [
        "sns.scatterplot(x=churn_df['Contacts'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brD2QMlSvv2Q"
      },
      "source": [
        "sns.scatterplot(x=churn_df['Yearly_equip_failure'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bi-rQgpnvv2Q"
      },
      "source": [
        "sns.scatterplot(x=churn_df['DummyTechie'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ6bb-icvv2Q"
      },
      "source": [
        "sns.scatterplot(x=churn_df['Tenure'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KxjRkwKovv2Q"
      },
      "source": [
        "sns.scatterplot(x=churn_df['MonthlyCharge'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxZ0RQzSvv2Q"
      },
      "source": [
        "sns.scatterplot(x=churn_df['Bandwidth_GB_Year'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu0wqZL-vv2R"
      },
      "source": [
        "sns.scatterplot(x=churn_df['TimelyResponse'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp7g-d3Tvv2R"
      },
      "source": [
        "sns.scatterplot(x=churn_df['Fixes'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD3o9HJfvv2R"
      },
      "source": [
        "sns.scatterplot(x=churn_df['Replacements'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOHyhTeJvv2R"
      },
      "source": [
        "sns.scatterplot(x=churn_df['Reliability'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGjNWfSQvv2R"
      },
      "source": [
        "sns.scatterplot(x=churn_df['Options'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGtJ8yxovv2R"
      },
      "source": [
        "sns.scatterplot(x=churn_df['Respectfulness'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co96ia9tvv2R"
      },
      "source": [
        "sns.scatterplot(x=churn_df['Courteous'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XaS8VWLvv2R"
      },
      "source": [
        "sns.scatterplot(x=churn_df['Listening'], y=churn_df['DummyChurn'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aa-1EJvvv2S"
      },
      "source": [
        "sns.scatterplot(x=churn_df['MonthlyCharge'], y=churn_df['Outage_sec_perweek'], color='red')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaZ5sZFKvv2S"
      },
      "source": [
        "## Scatterplot Summary\n",
        "### &emsp; These scatterplots suggest no correlation between a customer churning (Churn = 1) & any of our continous user data points or categorical responses to survey data points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blIxLFACvv2S"
      },
      "source": [
        "### <span style=\"color:green\"><b>C5. Prepared Dataset</b>:</span>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b97mTnNvv2S"
      },
      "source": [
        "# Extract Clean dataset\n",
        "churn_df.to_csv('churn_prepared_log.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F82Jz6sEvv2S"
      },
      "source": [
        "### <span style=\"color:green\"><b>D1. Initial Model</b></span>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1of-Ba11vv2S"
      },
      "source": [
        "\"\"\"Develop the initial estimated regression equation that could be used to predict the probability of customer churn, given the only continuous variables\"\"\"\n",
        "churn_df = pd.read_csv('churn_prepared_log.csv')\n",
        "churn_df['intercept'] = 1\n",
        "churn_df = pd.get_dummies(churn_df, drop_first=True)\n",
        "\n",
        "churn_logit_model = sm.Logit(churn_df['DummyChurn'], churn_df[['Children', 'Age', \n",
        "                                                               'Income',\n",
        "                                                               'Outage_sec_perweek', \n",
        "                                                               'Email', 'Contacts',\n",
        "                                                               'Yearly_equip_failure', \n",
        "                                                               'Tenure', 'MonthlyCharge',\n",
        "                                                               'Bandwidth_GB_Year',\n",
        "                                                               'TimelyResponse', 'Fixes', \n",
        "                                                               'Replacements', 'Reliability', \n",
        "                                                               'Options', 'Respectfulness', \n",
        "                                                               'Courteous', 'Listening', \n",
        "                                                               'intercept']]).fit()\n",
        "print(churn_logit_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuIV9dorvv2S"
      },
      "source": [
        "## Dummy Variables\n",
        "### Now, we will run a model including all encoded categorical dummy variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtvc12r1vv2S"
      },
      "source": [
        "\"\"\"\"Model including all dummy variables\"\"\"\n",
        "churn_df = pd.read_csv('data/churn_prepared_log.csv')\n",
        "churn_df['intercept'] = 1\n",
        "churn_df = pd.get_dummies(churn_df, drop_first=True)\n",
        "\n",
        "churn_logit_model2 = sm.Logit(churn_df['DummyChurn'], churn_df[['Children', 'Age', \n",
        "                                                               'Income', 'Outage_sec_perweek', \n",
        "                                                               'Email', 'Contacts',\n",
        "                                                               'Yearly_equip_failure', \n",
        "                                                               'DummyTechie', 'DummyContract', \n",
        "                                                               'DummyPort_modem', 'DummyTablet', \n",
        "                                                               'DummyInternetService', 'DummyPhone', \n",
        "                                                               'DummyMultiple', 'DummyOnlineSecurity', \n",
        "                                                               'DummyOnlineBackup', 'DummyDeviceProtection', \n",
        "                                                               'DummyTechSupport', 'DummyStreamingTV', \n",
        "                                                               'DummyPaperlessBilling',\n",
        "                                                               'Tenure', 'MonthlyCharge', 'Bandwidth_GB_Year', \n",
        "                                                               'TimelyResponse', 'Fixes', \n",
        "                                                               'Replacements', 'Reliability', \n",
        "                                                               'Options', 'Respectfulness', \n",
        "                                                               'Courteous', 'Listening', \n",
        "                                                               'intercept']]).fit()\n",
        "print(churn_logit_model2.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgrvaBftvv2T"
      },
      "source": [
        "## Early Model Comparison\n",
        "### Following the second run of our MLE model, our pseudo R went up from 0.4473 to 0.5296 as we added in our categorical dummy variables to our continuous variables. &nbsp; We will take that as a good sign that some of the explanation of our variance is within the categorical data points. &nbsp; We will use those 31 variables as our initial regression equation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdQySbqPvv2T"
      },
      "source": [
        "### Initial Multiple Linear Regression Model\n",
        "With <b><i>31</i></b> independent variables (18 continuous & 13 categorical): \n",
        "<br><br>&emsp;<span style=\"color:gold\"><b><i>y</i></b> &nbsp; = &nbsp; -5.8583 + (-0.0395 * Children) + (0.0069 * Age) + (1.199e-07 * Income) + \n",
        "<br> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp; (-0.0020 * Outage_sec_perweek) + (-0.0015 * Email) + (0.0301 * Contacts) + \n",
        "<br> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp; (-0.0308 * Yearly_equip_failure) + (0.7956 * DummyTechie) + (-2.295 * DummyContract) + \n",
        "<br> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp; (0.161 * DummyPort_modem) + (-0.0796 * DummyTablet) + (-1.4252 * DummyInternetService) + \n",
        "<br> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp; (-0.3157 * DummyPhone) + (-0.2908 * DummyMultiple) + (-0.3280 * DummyOnlineSecurity) + \n",
        "<br> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp; (-0.5125 * DummyOnlineBackup) + (-0.41 * DummyDeviceProtection) + (-0.3461 * DummyTechSupport) + \n",
        "<br> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp; (0.0311 * DummyStreamingTV) + (0.1126 * DummyPaperlessBilling) + (-0.2043 * Tenure) + \n",
        "<br> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp; (0.0461 * MonthlyCharge) + (0.0013 * Bandwidth_GB_Year) + (-0.0167 * TimelyResponse) + \n",
        "<br> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp; (0.0143 * Fixes) + (-0.0158 * Replacements) + (-0.025 * Reliability) + \n",
        "<br> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp; (-0.0341 * Options) + (-0.0309 * Respectfulness) + (0.0047 * Courteous) + \n",
        "<br> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp; (-0.009 * Listening)</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhgbyCsjvv2T"
      },
      "source": [
        "### <span style=\"color:green\"><b>D2. Justification of Model Reduction</b></span>\n",
        "&emsp; Based on the above MLE model we created, we have a pseudo R value = 0.5296, which is clearly not very good for the variance of our model. &nbsp; Also, coefficients on the above model are very low (less than 0.5) with the exception of variables DummyTechie, DummyContract, DummyInternetService & DummyOnlineBackup. &nbsp; Those variables also have p-values less than 0.000 & appear, therefore, significant.  \n",
        "&emsp; Subsequently, let us choose a p-value of 0.05 & include all variables with p-values &#8804; 0.05. &nbsp; We will remove any predictor variable with a p-value greater than 0.05 as not statistically significant to our model.\n",
        "\n",
        "<br>Our next MLE run will include the <b>continuous predictor variables</b>: \n",
        "\n",
        "* Age  \n",
        "* Tenure\n",
        "* MonthlyCharge\n",
        "* Bandwidth_GB_Year\n",
        "\n",
        "And, <b>categorical predictor variables</b>:\n",
        "\n",
        "* DummyTechie \n",
        "* DummyContract\n",
        "* DummyPort_modem\n",
        "* DummyInternetService\n",
        "* DummyPhone \n",
        "* DummyMultiple\n",
        "* DummyOnlineSecurity\n",
        "* DummyOnlineBackup\n",
        "* DummyDeviceProtection\n",
        "* DummyTechSupport\n",
        "\n",
        "We will run that reduced number of predictor variables against our DummyChurn dependent variable in another MLE model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6dbaaJjvv2T"
      },
      "source": [
        "### <span style=\"color:green\"><b>D3. Reduced Multiple Regression Model</b></span>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs3v21M0vv2T",
        "outputId": "8708ced2-ea28-4638-d995-97d6b2c468e3"
      },
      "source": [
        "# Run reduced OLS multiple regression\n",
        "churn_df['intercept'] = 1\n",
        "churn_logit_model_reduced = sm.Logit(churn_df['DummyChurn'], \n",
        "                                     churn_df[['Children', 'Age', 'DummyTechie', 'DummyContract', 'DummyPort_modem', \n",
        "                                               'DummyInternetService', 'DummyPhone','DummyMultiple', \n",
        "                                               'DummyOnlineSecurity', 'DummyOnlineBackup', 'DummyDeviceProtection', \n",
        "                                               'DummyTechSupport', 'Tenure', 'MonthlyCharge', 'Bandwidth_GB_Year', \n",
        "                                               'intercept']]).fit()\n",
        "print(churn_logit_model_reduced.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.272362\n",
            "         Iterations 8\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:             DummyChurn   No. Observations:                10000\n",
            "Model:                          Logit   Df Residuals:                     9984\n",
            "Method:                           MLE   Df Model:                           15\n",
            "Date:                Wed, 21 Jul 2021   Pseudo R-squ.:                  0.5290\n",
            "Time:                        10:31:53   Log-Likelihood:                -2723.6\n",
            "converged:                       True   LL-Null:                       -5782.2\n",
            "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
            "=========================================================================================\n",
            "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
            "-----------------------------------------------------------------------------------------\n",
            "Children                 -0.0391      0.018     -2.221      0.026      -0.074      -0.005\n",
            "Age                       0.0070      0.002      3.735      0.000       0.003       0.011\n",
            "DummyTechie               0.7970      0.089      8.996      0.000       0.623       0.971\n",
            "DummyContract            -2.2895      0.103    -22.136      0.000      -2.492      -2.087\n",
            "DummyPort_modem           0.1598      0.068      2.339      0.019       0.026       0.294\n",
            "DummyInternetService     -1.4240      0.125    -11.359      0.000      -1.670      -1.178\n",
            "DummyPhone               -0.3193      0.116     -2.749      0.006      -0.547      -0.092\n",
            "DummyMultiple            -0.2964      0.077     -3.857      0.000      -0.447      -0.146\n",
            "DummyOnlineSecurity      -0.3303      0.073     -4.497      0.000      -0.474      -0.186\n",
            "DummyOnlineBackup        -0.5146      0.072     -7.125      0.000      -0.656      -0.373\n",
            "DummyDeviceProtection    -0.4075      0.070     -5.790      0.000      -0.545      -0.270\n",
            "DummyTechSupport         -0.3555      0.073     -4.892      0.000      -0.498      -0.213\n",
            "Tenure                   -0.2049      0.021     -9.770      0.000      -0.246      -0.164\n",
            "MonthlyCharge             0.0463      0.002     25.620      0.000       0.043       0.050\n",
            "Bandwidth_GB_Year         0.0013      0.000      5.279      0.000       0.001       0.002\n",
            "intercept                -6.1973      0.236    -26.280      0.000      -6.659      -5.735\n",
            "=========================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS7m0Hskvv2T"
      },
      "source": [
        "### Reduced Logistic Regression Model\n",
        "With <b>15</b> independent variables (5 continuous & 10 categorical):\n",
        "\n",
        "<br><br>&emsp;<span style=\"color:gold\"><b><i>y</i></b> &nbsp; = &nbsp; -6.1973 + (-0.0391 * Children) + (0.0070 * Age) + \n",
        "(0.7970 * DummyTechie) + \n",
        "<br> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp; (-2.2895 * DummyContract) + (0.1598 * DummyPort_modem) + (-1.4240 * DummyInternetService) + \n",
        "<br> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp; (-0.3193 * DummyPhone) + (-0.2964 * DummyMultiple) + (-0.3303 * DummyOnlineSecurity) + \n",
        "<br> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp; (-0.5146 * DummyOnlineBackup) + (-0.41 * DummyDeviceProtection) + (-0.3461 * DummyTechSupport) + \n",
        "<br> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp; (-0.2049 * Tenure) + (0.0463 * MonthlyCharge) + (0.0013 * Bandwidth_GB_Year)</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3-6KZOIvv2T"
      },
      "source": [
        "### <span style=\"color:green\"><b>E1. Model Comparison</b></span>\n",
        "The second model still explains 52% of variance, as demonstrated by the pseudo R, even though we have reduced the number of variables in half (from 31 to 15).  We have suggested an alpha threshold of 0.05 to retain predictor variables.  We can see that, as Churn = 1 & that our majority of our dummy variables (which are additional services that a customer may add on to their contract) have negative values.  \n",
        "&emsp; What is important to decision-makers & marketers is that those inverse relationships suggest that as a customer subscribes to more services that the company provided, an additional port modem or online backup for example, they are less likely to churn & leave the company.  Cleary, it is in the best interest of retaining customers to provide them with more services & improve their experience with the company by helping customers understand all the services that are available to them as a subscriber, not simply mobile phone service."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nqu4hlwvv2T"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH9hvjYbvv2T"
      },
      "source": [
        "# Import the prepared dataset\n",
        "dataset = pd.read_csv('data/churn_prepared_log.csv')\n",
        "X = dataset.iloc[:, 1:-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJpuzxcKvv2T"
      },
      "source": [
        "# Split the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvWcdmNuvv2T"
      },
      "source": [
        "# Training the Logistic Regression model on the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGhHn3gUvv2U"
      },
      "source": [
        "# Predict the Test set results\n",
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6mCn478vv2U"
      },
      "source": [
        "# Make the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVqRYF93vv2U"
      },
      "source": [
        "## Compute the accuracy with k-Fold Cross Validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
        "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
        "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCXGK2uxvv2U"
      },
      "source": [
        "y_predict_test = classifier.predict(X_test)\n",
        "cm2 = confusion_matrix(y_test, y_predict_test)\n",
        "sns.heatmap(cm2, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiVFTq1Svv2U"
      },
      "source": [
        "### Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX7eyhvbvv2U"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_predict_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoPUh7e2vv2U"
      },
      "source": [
        "### <span style=\"color:green\"><b>E2. Output & Calculations</b></span>\n",
        "Calculations & code output above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nja8VkdAvv2U"
      },
      "source": [
        "### <span style=\"color:green\"><b>E3. Code</b></span>\n",
        "All code for analysis include above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT4TS9uxvv2U"
      },
      "source": [
        "### <span style=\"color:green\"><b>F1. Results</b></span>\n",
        "The final multiple regression equation with <b>15</b> predictor variables: \n",
        "<br><br>&emsp;<span style=\"color:gold\">y = -6.1973 - 0.0391 * Children + 0.0070 * Age + 0.7970 * DummyTechie - 2.2895 * DummyContract + 0.1598 * DummyPort_modem - 1.4240 * DummyInternetService - 0.3193 * DummyPhone - 0.2964 * DummyMultiple - 0.3303 * DummyOnlineSecurity - 0.5146 * DummyOnlineBackup - 0.4075 * DummyDeviceProtection - 0.3555 * DummyTechSupport - 0.2049 * Tenure + 0.0463 * MonthlyCharge + 0.0013 * Bandwidth_GB_Year</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OjZoiaxvv2U"
      },
      "source": [
        "### <span style=\"color:green\"><b>F2. Recommendations</b></span>\n",
        "It is critical that decision-makers & marketers understand that there is inverse relationship between our target variable of Churn & several of our predictor variables.  This suggests that as a customer subscribes to more services that the company provided, an additional port modem or online backup for example, they are less likely to leave the company. Clearly, it is the best interest of retaining customers to provide them with more services & improve their experience with the company by helping customers understand all the services that are available to them as a subscriber, not simple mobile phone service.  Given the negative coefficients of additional services, we suggest additional marketing efforts for contracts & internet services as those with contract appear less likely to leave the company.  \n",
        "&emsp; Also, with such a direct linear relationship between bandwidth used yearly & tenure with the telecom company it makes sense to suggest the company do everything within marketing & customer service capability to retain the customers gained as the longer they stay with the company the more bandwidth they tend to use.  This would include making sure that fixes to customer problems are prompt & that the equipment provided is high quality to avoid fewer replacements of equipment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7xqLWrXvv2V"
      },
      "source": [
        "### <span style=\"color:green\"><b>G. Video</b></span>\n",
        "<span style=\"color:red\">link</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf89bOWnvv2V"
      },
      "source": [
        "### <span style=\"color:green\">H. Sources for Third-Party Code</span>\n",
        "\n",
        "GeeksForGeeks. &ensp; (2019, July 4). &ensp; <i>Python | Visualize missing values (NaN) values using Missingno Library</i>. &ensp; GeeksForGeeks. &ensp; https://www.geeksforgeeks.org/python-visualize-missing-values-nan-values-using-missingno-library/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BvMkm75vv2V"
      },
      "source": [
        "### <span style=\"color:green\">I. Sources</span>\n",
        "\n",
        "CBTNuggets. &ensp; (2018, September 20). &ensp; <i>Why Data Scientists Love Python</i>. &ensp; https://www.cbtnuggets.com/blog/technology/data/why-data-scientists-love-python\n",
        "\n",
        "<br> Massaron, L. & Boschetti, A. &ensp; (2016). &ensp; <i>Regression Analysis with Python</i>. &ensp; Packt Publishing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81H8AFzIvv2V"
      },
      "source": [
        "!wget -nc https://raw.githubusercontent.com/brpy/colab-pdf/master/colab_pdf.py\n",
        "from colab_pdf import colab_pdf\n",
        "colab_pdf('D208_Performance_Assessment_NBM2_Task_2.ipynb')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}